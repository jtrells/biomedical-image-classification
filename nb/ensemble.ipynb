{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reference to ../src\n",
    "import os\n",
    "import sys\n",
    "module_path = os.path.abspath(os.path.join('../src'))\n",
    "if module_path not in sys.path:\n",
    "    sys.path.append(module_path)\n",
    "\n",
    "import pandas as pd\n",
    "import csv\n",
    "import os\n",
    "\n",
    "from dataset.MicroscopyTrainDataLoader import MicroscopyTrainDataLoader\n",
    "from experiments.microscopy.microscopy import experiment, get_model\n",
    "import torch\n",
    "from torch.utils.data import DataLoader\n",
    "import torch.nn as nn\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "import numpy as np; np.random.seed(0)\n",
    "import seaborn as sns; sns.set()\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "OUTPUT_PATH = '../labels/microscopy.csv'\n",
    "JSON_INPUT_PATH = \"../src/experiments/microscopy/shallow-resnet50.json\"\n",
    "JSON_OUTPUT_PATH = \"../src/experiments/microscopy/out_shallow_resnet50.json\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'resnet50.layer4-2': {'id': 'serene-brook-273', 'layers': [3, 4, 6, 3]},\n",
       " 'resnet50.layer4-1': {'id': 'clean-grass-271', 'layers': [3, 4, 6, 2]},\n",
       " 'resnet50.layer4-0': {'id': 'apricot-tree-269', 'layers': [3, 4, 6, 1]},\n",
       " 'resnet50.layer3-5': {'id': 'cerulean-cosmos-267', 'layers': [3, 4, 6, 0]},\n",
       " 'resnet50.layer3-4': {'id': 'summer-fog-265', 'layers': [3, 4, 5, 0]},\n",
       " 'resnet50.layer3-3': {'id': 'toasty-universe-263', 'layers': [3, 4, 4, 0]},\n",
       " 'resnet50.layer3-2': {'id': 'proud-breeze-261', 'layers': [3, 4, 3, 0]},\n",
       " 'resnet50.layer3-1': {'id': 'fragrant-glitter-258', 'layers': [3, 4, 2, 0]},\n",
       " 'resnet50.layer3-0': {'id': 'tough-wave-256', 'layers': [3, 4, 1, 0]},\n",
       " 'resnet50.layer2-3': {'id': 'crisp-shape-254', 'layers': [3, 4, 0, 0]},\n",
       " 'resnet50.layer2-2': {'id': 'magic-meadow-252', 'layers': [3, 3, 0, 0]},\n",
       " 'resnet50.layer2-1': {'id': 'comic-tree-250', 'layers': [3, 2, 0, 0]},\n",
       " 'resnet50.layer2-0': {'id': 'unique-lion-247', 'layers': [3, 1, 0, 0]},\n",
       " 'resnet50.layer1-2': {'id': 'wobbly-morning-246', 'layers': [3, 0, 0, 0]},\n",
       " 'resnet50.layer1-1': {'id': 'genial-sound-244', 'layers': [2, 0, 0, 0]},\n",
       " 'resnet50.layer1-0': {'id': 'sandy-cosmos-242', 'layers': [1, 0, 0, 0]}}"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import json\n",
    "\n",
    "with open(JSON_INPUT_PATH) as json_file:\n",
    "    models = json.load(json_file)\n",
    "\n",
    "models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_shallow_model(model_id, model_dict):\n",
    "    model_name, experiment_name = model_id.split('.')\n",
    "    model = get_model(model_name, \"shallow\", 4, layers=model_dict[model_id]['layers'], pretrained=True)\n",
    "    \n",
    "    checkpoint = torch.load('../outputs/{0}/checkpoint.pt'.format(model_dict[model_id]['id']))\n",
    "    model.load_state_dict(checkpoint)\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "resnet50_4_2 = load_shallow_model('resnet50.layer4-2', models)\n",
    "resnet50_4_1 = load_shallow_model('resnet50.layer4-1', models)\n",
    "resnet50_4_0 = load_shallow_model('resnet50.layer4-0', models)\n",
    "resnet50_3_5 = load_shallow_model('resnet50.layer3-5', models)\n",
    "resnet50_3_4 = load_shallow_model('resnet50.layer3-4', models)\n",
    "resnet50_3_3 = load_shallow_model('resnet50.layer3-3', models)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn.functional as F\n",
    "\n",
    "class MyEnsemble(nn.Module):\n",
    "    def __init__(self, model1, model2, model3, model4, model5, model6, nb_classes=4):\n",
    "        super(MyEnsemble, self).__init__()\n",
    "        self.model1 = model1\n",
    "        self.model2 = model2\n",
    "        self.model3 = model3\n",
    "        self.model4 = model4\n",
    "        self.model5 = model5\n",
    "        self.model6 = model6\n",
    "        # Remove last linear layer\n",
    "        self.model1.fc = nn.Identity()\n",
    "        self.model2.fc = nn.Identity()\n",
    "        self.model3.fc = nn.Identity()\n",
    "        self.model4.fc = nn.Identity()\n",
    "        self.model5.fc = nn.Identity()\n",
    "        self.model6.fc = nn.Identity()\n",
    "        \n",
    "        # Create new classifier\n",
    "        self.classifier = nn.Linear(2048+2048+2048+1024+1024+1024, nb_classes)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x1 = self.model1(x.clone())  # clone to make sure x is not changed by inplace methods\n",
    "        x1 = x1.view(x1.size(0), -1)\n",
    "        x2 = self.model2(x)\n",
    "        x2 = x2.view(x2.size(0), -1)\n",
    "        x3 = self.model3(x)\n",
    "        x3 = x3.view(x3.size(0), -1)\n",
    "        x4 = self.model4(x)\n",
    "        x4 = x4.view(x4.size(0), -1)\n",
    "        x5 = self.model5(x)\n",
    "        x5 = x5.view(x5.size(0), -1)\n",
    "        x6 = self.model6(x)\n",
    "        x6 = x6.view(x6.size(0), -1)\n",
    "        \n",
    "        x = torch.cat((x1, x2, x3, x4, x5, x6), dim=1)\n",
    "        \n",
    "        x = self.classifier(F.relu(x))\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "ensemble = MyEnsemble(resnet50_4_2, resnet50_4_1, resnet50_4_0, resnet50_3_5, resnet50_3_4, resnet50_3_3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "checkpoint = torch.load('/workspace/outputs/{0}/checkpoint.pt'.format('prime-river-402'))\n",
    "ensemble.load_state_dict(checkpoint)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "OUTPUT_PATH = '../labels/microscopy.csv'\n",
    "loader = MicroscopyTrainDataLoader(OUTPUT_PATH)\n",
    "test_dataset = loader.get_test_dataset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test(model):\n",
    "    device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    \n",
    "    trainable_params = sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "    total_params = sum(p.numel() for p in model.parameters())\n",
    "    model = model.to(device)\n",
    "    \n",
    "    model.eval()\n",
    "    \n",
    "    kwargs = {'num_workers': 16, 'pin_memory': True} if torch.cuda.is_available() else {}\n",
    "    test_loader = DataLoader(test_dataset, batch_size=32, shuffle=False, **kwargs)\n",
    "    \n",
    "    test_loss, n_iter = 0, 0\n",
    "    total, correct = 0, 0\n",
    "    \n",
    "    y_true = []\n",
    "    y_pred = []\n",
    "    img_names = []\n",
    "    \n",
    "    for images, labels, img_path in test_loader:         \n",
    "        y_true += labels\n",
    "        img_names += img_path\n",
    "\n",
    "        images = images.to(device)\n",
    "        labels = labels.to(device)\n",
    "\n",
    "        outputs = model(images)\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        y_pred += predicted.cpu()\n",
    "\n",
    "        loss = criterion(outputs, labels)\n",
    "\n",
    "        total += labels.size(0)\n",
    "        correct += torch.sum(predicted == labels.data)\n",
    "        test_loss += loss.item()\n",
    "        n_iter += 1\n",
    "\n",
    "    acc = 100 * torch.true_divide(correct, total)\n",
    "    average_loss = test_loss / n_iter\n",
    "    \n",
    "    target_names = test_dataset.codec.classes_\n",
    "    print(classification_report(y_true, y_pred, target_names=target_names, digits=4))\n",
    "    \n",
    "    return acc.cpu(), average_loss, y_true, y_pred, img_names, trainable_params, total_params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "        DMEL     0.6452    0.4545    0.5333        88\n",
      "        DMFL     0.9371    0.9437    0.9404       284\n",
      "        DMLI     0.9363    0.9802    0.9578       405\n",
      "        DMTR     0.7624    0.8021    0.7817        96\n",
      "\n",
      "    accuracy                         0.8958       873\n",
      "   macro avg     0.8202    0.7951    0.8033       873\n",
      "weighted avg     0.8881    0.8958    0.8900       873\n",
      "\n"
     ]
    }
   ],
   "source": [
    "acc, avg_loss, y_true, y_pred, img_names, trainable_params, total_params = test(ensemble)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.45454545, 0.94366197, 0.98024691, 0.80208333])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "import numpy as np\n",
    "\n",
    "cm = confusion_matrix(y_true, y_pred)\n",
    "cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
    "cm.diagonal()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'cm' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-f0659ae03bdc>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mseaborn\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0msns\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0msns\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mheatmap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcm\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mannot\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'cm' is not defined"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
