{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "module_path = os.path.abspath(os.path.join('../src'))\n",
    "if module_path not in sys.path:\n",
    "    sys.path.append(module_path)\n",
    "    \n",
    "from models.CaptionModalityClassifier import CaptionModalityClassifier\n",
    "from dataset.CaptionDataModule import CaptionDataModule\n",
    "from utils.caption_utils import load_embedding_matrix\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "MAX_NUMBER_WORDS = 20000       # number of words to consider from embeddings vocabulary\n",
    "MAX_WORDS_PER_SENTENCE = 300   # sentence maximum length\n",
    "WORD_DIMENSION = 300           # number of features per embedding\n",
    "NUM_CLASSES = 4                # 4 microscopy classes\n",
    "\n",
    "DATA_PATH = '/workspace/data/multimodality_classification.csv'\n",
    "EMBEDDINGS = '/workspace/data/embeddings'\n",
    "BATCH_SIZE = 32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "dm = CaptionDataModule(BATCH_SIZE, DATA_PATH, MAX_NUMBER_WORDS, MAX_WORDS_PER_SENTENCE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "dm.prepare_data()\n",
    "dm.setup()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7221"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dm.vocab_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dimension: 300; found 400000 word vectors.\n"
     ]
    }
   ],
   "source": [
    "embeddings_dict = load_embedding_matrix(EMBEDDINGS, WORD_DIMENSION)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "if dm.vocab_size < MAX_NUMBER_WORDS:\n",
    "    MAX_NUMBER_WORDS = dm.vocab_size + 1\n",
    "embedding_matrix = np.zeros((MAX_NUMBER_WORDS, WORD_DIMENSION))\n",
    "    \n",
    "for word, idx in dm.word_index.items():    \n",
    "    if idx < MAX_NUMBER_WORDS:\n",
    "        word_embedding = embeddings_dict.get(word)\n",
    "        if word_embedding is not None:\n",
    "            embedding_matrix[idx] = word_embedding\n",
    "        else:\n",
    "            embedding_matrix[idx] = np.random.randn(WORD_DIMENSION)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = CaptionModalityClassifier(\n",
    "                 max_input_length=MAX_WORDS_PER_SENTENCE,\n",
    "                 vocab_size=MAX_NUMBER_WORDS,\n",
    "                 embedding_dim=WORD_DIMENSION,\n",
    "                 filters=100,\n",
    "                 embeddings=embedding_matrix,\n",
    "                 num_classes=NUM_CLASSES,\n",
    "                 train_embeddings=True,\n",
    "                 lr=1e-4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "                Logging results to <a href=\"https://wandb.com\" target=\"_blank\">Weights & Biases</a> <a href=\"https://docs.wandb.com/integrations/jupyter.html\" target=\"_blank\">(Documentation)</a>.<br/>\n",
       "                Project page: <a href=\"https://app.wandb.ai/jtrells/pytorchlightning\" target=\"_blank\">https://app.wandb.ai/jtrells/pytorchlightning</a><br/>\n",
       "                Run page: <a href=\"https://app.wandb.ai/jtrells/pytorchlightning/runs/6kfqqrj0\" target=\"_blank\">https://app.wandb.ai/jtrells/pytorchlightning/runs/6kfqqrj0</a><br/>\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Failed to query for notebook name, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Wandb version 0.10.1 is available!  To upgrade, please run:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:  $ pip install wandb --upgrade\n",
      "GPU available: True, used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "  | Name     | Type            | Params\n",
      "---------------------------------------------\n",
      "0 | accuracy | Accuracy        | 0     \n",
      "1 | CNNText  | CNNTextBackbone | 2 M   \n",
      "2 | fc       | Linear          | 1 K   \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dainty-snowflake-10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/pytorch_lightning/utilities/distributed.py:37: UserWarning: The dataloader, val dataloader 0, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 72 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  warnings.warn(*args, **kwargs)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=1.0, bar_style='info', description='Validation sanity check', layout=Layout…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/pytorch_lightning/utilities/distributed.py:37: UserWarning: The dataloader, train dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 72 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  warnings.warn(*args, **kwargs)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b40837576742496da95cae76304daae5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=1.0, bar_style='info', description='Training', layout=Layout(flex='2'), max…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=1.0, bar_style='info', description='Validating', layout=Layout(flex='2'), m…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/pytorch_lightning/utilities/distributed.py:37: UserWarning: You have set 4 number of classes if different from predicted (3) and target (2) number of classes\n",
      "  warnings.warn(*args, **kwargs)\n",
      "/usr/local/lib/python3.6/dist-packages/pytorch_lightning/utilities/distributed.py:37: UserWarning: You have set 4 number of classes if different from predicted (2) and target (2) number of classes\n",
      "  warnings.warn(*args, **kwargs)\n",
      "/usr/local/lib/python3.6/dist-packages/pytorch_lightning/utilities/distributed.py:37: UserWarning: You have set 4 number of classes if different from predicted (3) and target (3) number of classes\n",
      "  warnings.warn(*args, **kwargs)\n",
      "/usr/local/lib/python3.6/dist-packages/pytorch_lightning/utilities/distributed.py:37: UserWarning: \n",
      "                    When using EvalResult(early_stop_on=X) or TrainResult(early_stop_on=X) the\n",
      "                    'monitor' key of EarlyStopping has no effect.\n",
      "                    Remove EarlyStopping(monitor='val_early_stop_on) to fix')\n",
      "                \n",
      "  warnings.warn(*args, **kwargs)\n",
      "/usr/local/lib/python3.6/dist-packages/pytorch_lightning/utilities/distributed.py:37: RuntimeWarning: The metric you returned None must be a `torch.Tensor` instance, checkpoint not saved HINT: what is the value of loss in validation_epoch_end()?\n",
      "  warnings.warn(*args, **kwargs)\n",
      "/usr/local/lib/python3.6/dist-packages/pytorch_lightning/utilities/distributed.py:37: RuntimeWarning: Can save best model only with loss available, skipping.\n",
      "  warnings.warn(*args, **kwargs)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=1.0, bar_style='info', description='Validating', layout=Layout(flex='2'), m…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=1.0, bar_style='info', description='Validating', layout=Layout(flex='2'), m…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=1.0, bar_style='info', description='Validating', layout=Layout(flex='2'), m…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=1.0, bar_style='info', description='Validating', layout=Layout(flex='2'), m…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=1.0, bar_style='info', description='Validating', layout=Layout(flex='2'), m…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=1.0, bar_style='info', description='Validating', layout=Layout(flex='2'), m…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Saving latest checkpoint..\n",
      "Epoch 00007: early stopping triggered.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "from pytorch_lightning import Trainer\n",
    "from pytorch_lightning.callbacks import EarlyStopping\n",
    "from pytorch_lightning.loggers import WandbLogger\n",
    "import torch\n",
    "\n",
    "wandb_logger = WandbLogger(project='pytorchlightning')\n",
    "wandb_logger.experiment.save()\n",
    "print(wandb_logger.experiment.name)\n",
    "\n",
    "from pathlib import Path\n",
    "import os\n",
    "output_run_path = Path('./outputs') / wandb_logger.experiment.name \n",
    "os.makedirs(output_run_path, exist_ok=False)\n",
    "\n",
    "early_stop_callback = EarlyStopping(\n",
    "    monitor='val_loss',\n",
    "    min_delta=0.0,\n",
    "    patience=5,\n",
    "    verbose=True,\n",
    "    mode='min'\n",
    ")\n",
    "\n",
    "trainer = Trainer(gpus=1, early_stop_callback=early_stop_callback, logger=wandb_logger)\n",
    "trainer.fit(model, dm)\n",
    "\n",
    "torch.save(model.state_dict(), output_run_path / 'checkpoint.pt')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CaptionModalityClassifier(\n",
      "  (accuracy): Accuracy()\n",
      "  (CNNText): CNNTextBackbone(\n",
      "    (embeddings): Embedding(7222, 300)\n",
      "    (conv1d_1): Conv1d(300, 100, kernel_size=(3,), stride=(1,))\n",
      "    (relu1): ReLU()\n",
      "    (maxpool1): MaxPool1d(kernel_size=298, stride=298, padding=0, dilation=1, ceil_mode=False)\n",
      "    (conv1d_2): Conv1d(300, 100, kernel_size=(4,), stride=(1,))\n",
      "    (relu2): ReLU()\n",
      "    (maxpool2): MaxPool1d(kernel_size=297, stride=297, padding=0, dilation=1, ceil_mode=False)\n",
      "    (conv1d_3): Conv1d(300, 100, kernel_size=(5,), stride=(1,))\n",
      "    (relu3): ReLU()\n",
      "    (maxpool3): MaxPool1d(kernel_size=296, stride=296, padding=0, dilation=1, ceil_mode=False)\n",
      "    (dropout): Dropout(p=0.5, inplace=False)\n",
      "  )\n",
      "  (fc): Linear(in_features=300, out_features=4, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer.save_checkpoint(str(output_run_path / 'checkpoint2.pt'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "for x, y in dm.train_dataloader():\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-1.7381, -1.8300,  4.3508, -2.1198],\n",
       "        [-2.6980,  5.6537, -0.9756, -1.6762],\n",
       "        [ 1.2824, -2.3209, -1.8930, -0.1409],\n",
       "        [ 0.2061, -0.0753,  0.9443, -2.9515],\n",
       "        [-1.4886, -1.1114,  1.9535, -0.8665],\n",
       "        [-1.9705,  1.8203,  0.7369, -4.1768],\n",
       "        [-1.6583, -1.6331,  4.3735, -1.5197],\n",
       "        [-2.6538,  2.0293, -0.1982, -2.0733],\n",
       "        [-2.8402,  4.2675, -1.3636, -3.1963],\n",
       "        [ 3.6290, -0.9845, -2.5096, -1.0467],\n",
       "        [-2.1151,  3.6398, -2.3830, -1.5604],\n",
       "        [-2.9140,  4.4678, -1.2635, -0.8338],\n",
       "        [-2.6110,  2.7123, -3.9475, -1.9221],\n",
       "        [ 3.1484, -0.8544, -1.9854, -1.7324],\n",
       "        [-2.4984, -0.6780,  2.8862, -2.1551],\n",
       "        [-2.6663,  0.0908,  3.1733, -2.0626],\n",
       "        [-1.5970, -1.8656,  2.9868, -1.7876],\n",
       "        [ 1.1765, -2.5292,  1.9170, -1.8969],\n",
       "        [-3.0695, -2.4462, -1.2969,  4.1975],\n",
       "        [-2.6766,  3.7560, -2.0168, -1.2125],\n",
       "        [-1.5802, -1.5938,  4.4949, -1.2684],\n",
       "        [-2.9759, -1.0397,  4.8811, -1.6675],\n",
       "        [-1.6781,  5.6694, -2.8040, -2.7070],\n",
       "        [-2.8941, -2.1776,  3.9362, -2.7046],\n",
       "        [-1.7237,  3.3833, -4.4197,  0.7407],\n",
       "        [-2.6019,  2.8088,  2.2669, -4.5619],\n",
       "        [-1.9286,  6.6937, -3.8587, -2.4408],\n",
       "        [-1.6014,  2.0267, -3.7694,  0.5504],\n",
       "        [-3.5882, -2.9988,  6.7636, -1.9631],\n",
       "        [ 1.8282, -3.5462, -4.9994,  7.0987],\n",
       "        [-3.0844, -0.7180,  4.5425, -3.2207],\n",
       "        [-3.0004,  4.1831, -0.9232, -0.8079]], grad_fn=<AddmmBackward>)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = \n",
    "model(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
