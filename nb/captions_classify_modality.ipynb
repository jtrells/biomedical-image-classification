{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "module_path = os.path.abspath(os.path.join('../src'))\n",
    "if module_path not in sys.path:\n",
    "    sys.path.append(module_path)\n",
    "    \n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from models.kim_cnn import CNN1DText\n",
    "from utils.caption_utils import preprocess_training_data, load_embedding_matrix, clean_str\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from torch.utils.data import TensorDataset, DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "MAX_NUMBER_WORDS = 20000       # number of words to consider from embeddings vocabulary\n",
    "MAX_WORDS_PER_SENTENCE = 700   # sentence maximum length\n",
    "WORD_DIMENSION = 300           # number of features per embedding\n",
    "NUM_CLASSES = 4                # 4 microscopy classes\n",
    "\n",
    "DATA_PATH = '/workspace/data/multimodality_classification.csv'\n",
    "EMBEDDINGS = '/workspace/data/embeddings'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>ID</th>\n",
       "      <th>MODALITY</th>\n",
       "      <th>PATH</th>\n",
       "      <th>CAPTION</th>\n",
       "      <th>SET</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>201</td>\n",
       "      <td>1423-0127-16-7-1-1.jpg</td>\n",
       "      <td>DMEL</td>\n",
       "      <td>subfigure-classification/2016/train/DMEL/1423-...</td>\n",
       "      <td>Scanning electron microscope images of the TiO...</td>\n",
       "      <td>TRAIN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>202</td>\n",
       "      <td>1423-0127-16-7-1-2.jpg</td>\n",
       "      <td>DMEL</td>\n",
       "      <td>subfigure-classification/2016/train/DMEL/1423-...</td>\n",
       "      <td>Scanning electron microscope images of the TiO...</td>\n",
       "      <td>TRAIN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>203</td>\n",
       "      <td>1423-0127-16-7-1-4.jpg</td>\n",
       "      <td>DMEL</td>\n",
       "      <td>subfigure-classification/2016/train/DMEL/1423-...</td>\n",
       "      <td>Scanning electron microscope images of the TiO...</td>\n",
       "      <td>TRAIN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>204</td>\n",
       "      <td>1423-0127-16-7-1-5.jpg</td>\n",
       "      <td>DMEL</td>\n",
       "      <td>subfigure-classification/2016/train/DMEL/1423-...</td>\n",
       "      <td>Scanning electron microscope images of the TiO...</td>\n",
       "      <td>VAL</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>205</td>\n",
       "      <td>1423-0127-16-7-1-6.jpg</td>\n",
       "      <td>DMEL</td>\n",
       "      <td>subfigure-classification/2016/train/DMEL/1423-...</td>\n",
       "      <td>Scanning electron microscope images of the TiO...</td>\n",
       "      <td>TRAIN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0                      ID MODALITY  \\\n",
       "0         201  1423-0127-16-7-1-1.jpg     DMEL   \n",
       "1         202  1423-0127-16-7-1-2.jpg     DMEL   \n",
       "2         203  1423-0127-16-7-1-4.jpg     DMEL   \n",
       "3         204  1423-0127-16-7-1-5.jpg     DMEL   \n",
       "4         205  1423-0127-16-7-1-6.jpg     DMEL   \n",
       "\n",
       "                                                PATH  \\\n",
       "0  subfigure-classification/2016/train/DMEL/1423-...   \n",
       "1  subfigure-classification/2016/train/DMEL/1423-...   \n",
       "2  subfigure-classification/2016/train/DMEL/1423-...   \n",
       "3  subfigure-classification/2016/train/DMEL/1423-...   \n",
       "4  subfigure-classification/2016/train/DMEL/1423-...   \n",
       "\n",
       "                                             CAPTION    SET  \n",
       "0  Scanning electron microscope images of the TiO...  TRAIN  \n",
       "1  Scanning electron microscope images of the TiO...  TRAIN  \n",
       "2  Scanning electron microscope images of the TiO...  TRAIN  \n",
       "3  Scanning electron microscope images of the TiO...    VAL  \n",
       "4  Scanning electron microscope images of the TiO...  TRAIN  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(DATA_PATH, sep='\\t')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = df[df['SET']=='TRAIN']\n",
    "val_df = df[df['SET']=='VAL']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "x0_train, y0_train = train_df['CAPTION'].values, train_df['MODALITY'].values\n",
    "x0_val, y0_val = val_df['CAPTION'].values, val_df['MODALITY'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Data Vector:  (1864, 700)\n",
      "Validation Data Vector:  (466, 700)\n"
     ]
    }
   ],
   "source": [
    "(x_train, y_train), (x_val, y_val), word_index, _ = \\\n",
    "    preprocess_training_data(x0_train, y0_train, x0_val, y0_val, MAX_NUMBER_WORDS, MAX_WORDS_PER_SENTENCE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([   0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "        235,   77,  250,   36,    2,    1, 4521,   21, 2484,    5,    6,\n",
       "       3031,   10, 3032,    9, 4522, 4523, 2485,    2, 3032,   11,  685,\n",
       "       2263,    3, 4524,   16,  685, 2263,    3, 3031,    3,   17,  685,\n",
       "       2263,    3, 4525,   38,   73,   67,  905], dtype=int32)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'DMEL'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Scanning electron microscope images of the TiO 2  nanoparticles . (A) C150, (B) C200, (C) EDS elemental spectrum of C200, (D)  S. aureus  and UV100, (E)  S. aureus  and C150, and (F)  S. aureus  and C200. Scale bars: 100 nm.'"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x0_train[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'scanning electron microscope images of the tio 2 nanoparticles \\\\( a \\\\) c150 , \\\\( b \\\\) c200 , \\\\( c \\\\) eds elemental spectrum of c200 , \\\\( d \\\\) s aureus and uv100 , \\\\( e \\\\) s aureus and c150 , and \\\\( f \\\\) s aureus and c200 scale bars 100 nm'"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clean_str(x0_train[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dimension: 300; found 400000 word vectors.\n"
     ]
    }
   ],
   "source": [
    "embeddings_dict = load_embedding_matrix(EMBEDDINGS, 300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7221"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "MAX_NUMBER_WORDS = len(word_index) + 1\n",
    "MAX_NUMBER_WORDS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding_matrix = np.zeros((MAX_NUMBER_WORDS, WORD_DIMENSION))\n",
    "for word, idx in word_index.items():\n",
    "    if idx < MAX_NUMBER_WORDS:\n",
    "        word_embedding = embeddings_dict.get(word)\n",
    "        if word_embedding is not None:\n",
    "            embedding_matrix[idx] = word_embedding\n",
    "        else:\n",
    "            embedding_matrix[idx] = np.random.randn(WORD_DIMENSION)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "le = LabelEncoder()\n",
    "le.fit(y_train)\n",
    "\n",
    "x_train_tensor = torch.LongTensor(x_train)\n",
    "y_train_tensor = torch.LongTensor(le.transform(y_train))\n",
    "\n",
    "x_val_tensor = torch.LongTensor(x_val)\n",
    "y_val_tensor = torch.LongTensor(le.transform(y_val))\n",
    "\n",
    "kwargs = {'num_workers': 16, 'pin_memory': True} if torch.cuda.is_available() else {}\n",
    "\n",
    "train_dataset = TensorDataset(x_train_tensor, y_train_tensor)\n",
    "train_dataloader = DataLoader(train_dataset, batch_size=32, shuffle=True, **kwargs)\n",
    "\n",
    "val_dataset = TensorDataset(x_val_tensor, y_val_tensor)\n",
    "val_dataloader = DataLoader(val_dataset, batch_size=32, shuffle=False, **kwargs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = CNN1DText(MAX_WORDS_PER_SENTENCE,\n",
    "                  MAX_NUMBER_WORDS,\n",
    "                  WORD_DIMENSION,\n",
    "                  embedding_matrix,\n",
    "                  num_classes=NUM_CLASSES,\n",
    "                  train_embeddings=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "model = model.to(device)\n",
    "optimizer = torch.optim.Adam(model.parameters())\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "epochs = 50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train - epoch 0: loss: 0.9124659552412518, acc: 64.32403433476395\n",
      "val  - epoch 0: loss: 0.593061774969101, acc: 80.25751072961373\n",
      "train - epoch 1: loss: 0.47949724657050635, acc: 84.92489270386267\n",
      "val  - epoch 1: loss: 0.5000835130612056, acc: 81.54506437768241\n",
      "train - epoch 2: loss: 0.3943698199118598, acc: 87.33905579399142\n",
      "val  - epoch 2: loss: 0.49752609580755236, acc: 84.12017167381974\n",
      "train - epoch 3: loss: 0.3702757445684934, acc: 88.78755364806867\n",
      "val  - epoch 3: loss: 0.5458249593774478, acc: 83.2618025751073\n",
      "train - epoch 4: loss: 0.38185361103486204, acc: 88.19742489270386\n",
      "val  - epoch 4: loss: 0.5548598696788152, acc: 83.2618025751073\n",
      "train - epoch 5: loss: 0.34259729668245475, acc: 89.48497854077253\n",
      "val  - epoch 5: loss: 0.493646772702535, acc: 84.97854077253218\n",
      "train - epoch 6: loss: 0.32509999324457123, acc: 89.16309012875537\n",
      "val  - epoch 6: loss: 0.50447096824646, acc: 83.47639484978541\n",
      "train - epoch 7: loss: 0.35167551305839573, acc: 89.8068669527897\n",
      "val  - epoch 7: loss: 0.5599553753932317, acc: 82.40343347639485\n",
      "train - epoch 8: loss: 0.3350760802879172, acc: 89.32403433476395\n",
      "val  - epoch 8: loss: 0.5148282398780187, acc: 82.83261802575107\n",
      "train - epoch 9: loss: 0.3342074943801104, acc: 89.37768240343348\n",
      "val  - epoch 9: loss: 0.5198329466084639, acc: 81.54506437768241\n",
      "train - epoch 10: loss: 0.3182293088254282, acc: 89.96781115879828\n",
      "val  - epoch 10: loss: 0.5209597905476888, acc: 84.12017167381974\n",
      "train - epoch 11: loss: 0.34038835258807165, acc: 88.41201716738198\n",
      "val  - epoch 11: loss: 0.49528282980124155, acc: 84.12017167381974\n",
      "train - epoch 12: loss: 0.3195811131242978, acc: 89.37768240343348\n",
      "val  - epoch 12: loss: 0.4760967974861463, acc: 84.97854077253218\n",
      "train - epoch 13: loss: 0.31179635479288587, acc: 89.91416309012875\n",
      "val  - epoch 13: loss: 0.5025257309277852, acc: 83.69098712446352\n",
      "train - epoch 14: loss: 0.3058424853419853, acc: 89.21673819742489\n",
      "val  - epoch 14: loss: 0.5043182959159215, acc: 84.54935622317596\n",
      "train - epoch 15: loss: 0.2959289702318482, acc: 89.86051502145922\n",
      "val  - epoch 15: loss: 0.507819269100825, acc: 83.2618025751073\n",
      "train - epoch 16: loss: 0.29052967527660273, acc: 89.75321888412017\n",
      "val  - epoch 16: loss: 0.48549533983071647, acc: 83.90557939914163\n",
      "train - epoch 17: loss: 0.30445261602684603, acc: 89.00214592274678\n",
      "val  - epoch 17: loss: 0.541583976149559, acc: 81.97424892703863\n",
      "train - epoch 18: loss: 0.28870884101774735, acc: 90.02145922746782\n",
      "val  - epoch 18: loss: 0.5356852382421493, acc: 83.69098712446352\n",
      "train - epoch 19: loss: 0.2872599572322126, acc: 89.37768240343348\n",
      "val  - epoch 19: loss: 0.5051705633600553, acc: 84.12017167381974\n",
      "train - epoch 20: loss: 0.2783618608521203, acc: 89.48497854077253\n",
      "val  - epoch 20: loss: 0.5264633893966675, acc: 83.47639484978541\n",
      "train - epoch 21: loss: 0.2839778721079988, acc: 89.64592274678111\n",
      "val  - epoch 21: loss: 0.5232076972723008, acc: 81.75965665236052\n",
      "train - epoch 22: loss: 0.26826365481493836, acc: 89.5922746781116\n",
      "val  - epoch 22: loss: 0.5234628833830357, acc: 83.90557939914163\n",
      "train - epoch 23: loss: 0.2717677988743378, acc: 89.37768240343348\n",
      "val  - epoch 23: loss: 0.5365589290857316, acc: 83.47639484978541\n",
      "train - epoch 24: loss: 0.26907821132217424, acc: 90.02145922746782\n",
      "val  - epoch 24: loss: 0.5443429124852022, acc: 82.18884120171674\n",
      "train - epoch 25: loss: 0.27418362639718136, acc: 89.86051502145922\n",
      "val  - epoch 25: loss: 0.5414766331513723, acc: 83.90557939914163\n",
      "train - epoch 26: loss: 0.27546770340305266, acc: 89.5922746781116\n",
      "val  - epoch 26: loss: 0.5299708356459936, acc: 83.47639484978541\n",
      "train - epoch 27: loss: 0.2583812830054154, acc: 90.71888412017168\n",
      "val  - epoch 27: loss: 0.5181275685628255, acc: 83.2618025751073\n",
      "train - epoch 28: loss: 0.2539266919306779, acc: 90.34334763948497\n",
      "val  - epoch 28: loss: 0.5088571319977443, acc: 83.69098712446352\n",
      "train - epoch 29: loss: 0.24717058253995441, acc: 90.07510729613733\n",
      "val  - epoch 29: loss: 0.5300111562013626, acc: 82.40343347639485\n",
      "train - epoch 30: loss: 0.25771518544120303, acc: 90.28969957081546\n",
      "val  - epoch 30: loss: 0.5264432760576407, acc: 84.76394849785407\n",
      "train - epoch 31: loss: 0.26325733479806934, acc: 90.28969957081546\n",
      "val  - epoch 31: loss: 0.5227719401319821, acc: 83.2618025751073\n",
      "train - epoch 32: loss: 0.25370315146648276, acc: 89.5922746781116\n",
      "val  - epoch 32: loss: 0.5287483304738998, acc: 83.47639484978541\n",
      "train - epoch 33: loss: 0.25067002780861775, acc: 89.32403433476395\n",
      "val  - epoch 33: loss: 0.5335273032387098, acc: 84.33476394849785\n",
      "train - epoch 34: loss: 0.24551052259186568, acc: 90.66523605150215\n",
      "val  - epoch 34: loss: 0.526233896613121, acc: 85.1931330472103\n",
      "train - epoch 35: loss: 0.24157440169888028, acc: 90.3969957081545\n",
      "val  - epoch 35: loss: 0.5262197777628899, acc: 83.90557939914163\n",
      "train - epoch 36: loss: 0.2412594474094399, acc: 90.12875536480686\n",
      "val  - epoch 36: loss: 0.5143043041229248, acc: 83.2618025751073\n",
      "train - epoch 37: loss: 0.24577188984317294, acc: 89.91416309012875\n",
      "val  - epoch 37: loss: 0.5495230446259181, acc: 82.61802575107296\n",
      "train - epoch 38: loss: 0.2394424515255427, acc: 90.55793991416309\n",
      "val  - epoch 38: loss: 0.5318182756503423, acc: 83.04721030042919\n",
      "train - epoch 39: loss: 0.2513964512716916, acc: 89.96781115879828\n",
      "val  - epoch 39: loss: 0.5303756232062976, acc: 85.1931330472103\n",
      "train - epoch 40: loss: 0.2562814866334705, acc: 90.34334763948497\n",
      "val  - epoch 40: loss: 0.520777291059494, acc: 84.12017167381974\n",
      "train - epoch 41: loss: 0.22502089885331816, acc: 90.7725321888412\n",
      "val  - epoch 41: loss: 0.5212812398870786, acc: 85.62231759656652\n",
      "train - epoch 42: loss: 0.2456927641721095, acc: 90.12875536480686\n",
      "val  - epoch 42: loss: 0.5300364365180333, acc: 84.97854077253218\n",
      "train - epoch 43: loss: 0.23513300893670422, acc: 90.66523605150215\n",
      "val  - epoch 43: loss: 0.5516997853914897, acc: 83.90557939914163\n",
      "train - epoch 44: loss: 0.23717498930834108, acc: 90.07510729613733\n",
      "val  - epoch 44: loss: 0.557331754763921, acc: 84.12017167381974\n",
      "train - epoch 45: loss: 0.22661685463735612, acc: 90.55793991416309\n",
      "val  - epoch 45: loss: 0.5595508466164271, acc: 84.54935622317596\n",
      "train - epoch 46: loss: 0.23021745719647002, acc: 90.45064377682404\n",
      "val  - epoch 46: loss: 0.5371154968937238, acc: 85.83690987124463\n",
      "train - epoch 47: loss: 0.22365166903552364, acc: 90.1824034334764\n",
      "val  - epoch 47: loss: 0.5553758924206098, acc: 83.69098712446352\n",
      "train - epoch 48: loss: 0.23910079921706248, acc: 90.07510729613733\n",
      "val  - epoch 48: loss: 0.5411711672941844, acc: 84.76394849785407\n",
      "train - epoch 49: loss: 0.22215925460144625, acc: 90.7725321888412\n",
      "val  - epoch 49: loss: 0.5579160705208779, acc: 83.47639484978541\n"
     ]
    }
   ],
   "source": [
    "\n",
    "train_losses = []\n",
    "train_accs  = []\n",
    "val_losses = []\n",
    "val_accs  = []\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    # train step\n",
    "    model.train()\n",
    "\n",
    "    train_loss, n_iter = 0, 0\n",
    "    total, correct = 0, 0\n",
    "    \n",
    "    for x, y in train_dataloader:\n",
    "        x = x.to(device)\n",
    "        y = y.to(device)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        outputs = model(x)\n",
    "        loss = criterion(outputs, y)        \n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        \n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        total += y.size(0)\n",
    "        correct += torch.sum(predicted == y)\n",
    "        train_loss += loss.item()\n",
    "        n_iter += 1\n",
    "\n",
    "    epoch_acc = 100 * correct.item() / total\n",
    "    average_loss = train_loss / n_iter\n",
    "    train_losses.append(average_loss)\n",
    "    train_accs.append(epoch_acc)\n",
    "    \n",
    "    print(\"train - epoch {0}: loss: {1}, acc: {2}\".format(str(epoch), str(average_loss), str(epoch_acc)))\n",
    "    \n",
    "    # validation step\n",
    "    model.eval()\n",
    "\n",
    "    valid_loss, valid_n_iter = 0, 0\n",
    "    total, correct = 0, 0\n",
    "    \n",
    "    for x, y in val_dataloader:         \n",
    "        x = x.to(device)\n",
    "        y = y.to(device)\n",
    "\n",
    "        outputs = model(x)\n",
    "        loss = criterion(outputs, y)\n",
    "\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        \n",
    "        total += y.size(0)\n",
    "        correct += torch.sum(predicted == y)\n",
    "        valid_loss += loss.item()\n",
    "        valid_n_iter += 1\n",
    "\n",
    "    epoch_acc = 100 * correct.item() / total\n",
    "    average_loss = valid_loss / valid_n_iter\n",
    "    val_losses.append(average_loss)\n",
    "    val_accs.append(epoch_acc)\n",
    "    \n",
    "    print(\"val  - epoch {0}: loss: {1}, acc: {2}\".format(str(epoch), str(average_loss), str(epoch_acc)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "for x, y in val_dataloader:\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn.functional as F\n",
    "x = x.to(device)\n",
    "y = y.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "outputs = model(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([32, 4])"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "outputs.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.9252, device='cuda:0', grad_fn=<NllLossBackward>)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loss = F.cross_entropy(outputs, y)\n",
    "loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([32])\n",
      "tensor([0, 3, 1, 3, 3, 3, 3, 1, 1, 0, 0, 0, 0, 0, 3, 0, 0, 0, 3, 3, 0, 0, 1, 1,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0], device='cuda:0')\n",
      "tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0], device='cuda:0')\n",
      "tensor(0.5938)\n",
      "tensor(0.5938)\n"
     ]
    }
   ],
   "source": [
    "from pytorch_lightning.metrics.classification import Accuracy\n",
    "acc = Accuracy(4)\n",
    "_, predicted = torch.max(outputs.data, 1)\n",
    "print(predicted.shape)\n",
    "print(predicted)\n",
    "print(y)\n",
    "print(acc(outputs, y))\n",
    "print(acc(predicted, y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([32])"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.eval()\n",
    "y_true = []\n",
    "y_pred = []\n",
    "for x, y in val_dataloader:         \n",
    "    y_true += y\n",
    "    \n",
    "    x = x.to(device)\n",
    "    y = y.to(device)\n",
    "\n",
    "    outputs = model(x)\n",
    "    _, predicted = torch.max(outputs.data, 1)\n",
    "    y_pred += predicted.cpu()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 37,   5,   0,  10],\n",
       "       [  4, 163,   9,  12],\n",
       "       [  2,  13, 136,   6],\n",
       "       [  4,   4,   8,  53]])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "confusion_matrix(y_true, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "        DMEL     0.7872    0.7115    0.7475        52\n",
      "        DMFL     0.8811    0.8670    0.8740       188\n",
      "        DMLI     0.8889    0.8662    0.8774       157\n",
      "        DMTR     0.6543    0.7681    0.7067        69\n",
      "\n",
      "    accuracy                         0.8348       466\n",
      "   macro avg     0.8029    0.8032    0.8014       466\n",
      "weighted avg     0.8397    0.8348    0.8363       466\n",
      "\n"
     ]
    }
   ],
   "source": [
    "target_names = le.classes_\n",
    "print(classification_report(y_true, y_pred, digits=4, target_names=target_names))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
